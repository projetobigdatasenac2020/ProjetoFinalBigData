{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597427649549",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final Pós Graduação Big Data - Senac Rio - 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de importação das Bibliotecas utilizadas no durante todo o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas utilizadas para manipulação dos dados das paginas Web.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import zipfile\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicação do diretório para download dos arquivos Inep-Enem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicação do diretório desejado para download dos arquivos. \n",
    "#No exemplo, estamos salvando no diretório: C:\\Users\\Ricardo\\Downloads\n",
    "\n",
    "diretorio = input('Digite o diretório desejado para salvar os arquivos: ')\n",
    "os.chdir(r'{}'.format(diretorio))\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apos indicar o diretorio desejado, como boa pratica, sugerimos a criação da pasta onde será salvos os arquivos.\n",
    "#No exemplo, estamos salvando na pasta: MicrodadosEnem.'''\n",
    "\n",
    "url = 'http://inep.gov.br/microdados'\n",
    "\n",
    "pasta = input('Após indicação do diretório {}, informe o nome da pasta desejada para salvar os arquivos baixados da pagina {}: '.format(diretorio, url))\n",
    "\n",
    "try:\n",
    "    os.mkdir(pasta)\n",
    "    print('Pasta {} criada com sucesso!'.format(pasta))\n",
    "except FileExistsError as e:\n",
    "    print(f'Pasta {pasta} já existe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicação do diretório onde será salvo os arquivos baixados da url.\n",
    "\n",
    "os.chdir(r'{}\\{}'.format(diretorio, pasta))\n",
    "print('Os arquivos serão salvos no seguinte diretorio:', format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de Web Scraping no site do Inep, buscando os microdados do Enem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da variável que receberá todos os dados correspondente a varíavel \"url\".\n",
    "\n",
    "page = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da variável \"soup\", do pacote BeatifulSoup, que apresenta a estutura HTML da pagina que será trabalhada.\n",
    "\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No loop \"for\" abaixo, o realizaremos o filtro das tags desejadas.\n",
    "\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = link.get('href')\n",
    "    name = link.string\n",
    "    \n",
    "    print(theLink)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No processo abaixo, realizaremos o filtro das linhas, cujo o o tipo do arquivo desejado é *.zip.\n",
    "\n",
    "nomeArquivo = []\n",
    "typeFile = '.zip'\n",
    "i = 0\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = str(link.get('href')).lower()\n",
    "    name = link.string\n",
    "    if 'enem'in theLink:\n",
    "        if theLink[-4:] == typeFile:\n",
    "            print(theLink)\n",
    "            print(type(theLink))\n",
    "            print(name)\n",
    "            print(type(name))\n",
    "            nomeArquivo.append(theLink[39:-4].replace('/','_'))\n",
    "            print(type(nomeArquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processo de download dos arquivos desejados e salvos na na pasta indicada.\n",
    "\n",
    "i = 0\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = str(link.get('href')).lower()\n",
    "    name = link.string\n",
    "    if 'enem'in theLink:\n",
    "        if theLink[-4:] == typeFile:\n",
    "            if name is None:\n",
    "                title = 'SemTítulo' + typeFile\n",
    "            else:\n",
    "                title = nomeArquivo[i] + typeFile\n",
    "                i +=1\n",
    "            try:\n",
    "                with open(os.getcwd() + '/' + title,'r') as fileExists:\n",
    "                    print('Arquivo ' + title + ' existente no diretório '+ os.getcwd() + ' - ' + str(datetime.now()))\n",
    "                    fileExists.close()\n",
    "            except FileNotFoundError:\n",
    "                print('Download Iniciado - {}: '.format(datetime.now()) + title)\n",
    "                docFile = open(os.getcwd() + '/' + title,'wb')\n",
    "                docFile.write(urllib.request.urlopen(theLink).read())\n",
    "                docFile.close()\n",
    "                print('Download Concluído em {}'.format(datetime.now()))\n",
    "print('Não há mais arquivos para download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação do tamanho dos arquivos baixados.\n",
    "\n",
    "print('Apresentação Arquivos Enem baixados no díretório: ' + os.getcwd())\n",
    "contador = 0\n",
    "tamanhoTotal = 0\n",
    "tipo = '.zip'\n",
    "\n",
    "def formatarTamanho(tamanho):\n",
    "    base = 1024\n",
    "    kilo = base\n",
    "    mega = base ** 2\n",
    "    giga = base ** 3\n",
    "    tera = base ** 4\n",
    "    \n",
    "    if tamanho < kilo:\n",
    "        tamanho = base\n",
    "        texto = 'B'\n",
    "    elif tamanho < mega:\n",
    "        tamanho /= kilo\n",
    "        texto = 'K'\n",
    "    elif tamanho < giga:\n",
    "        tamanho /= mega\n",
    "        texto = 'M'\n",
    "    else:\n",
    "        tamanho < tera\n",
    "        tamanho /= giga\n",
    "        texto = 'G'\n",
    "    tamanho = round(tamanho, 2)\n",
    "    return f'{tamanho} {texto}'\n",
    "\n",
    "for raiz, diretorios, arquivos in os.walk(os.getcwd()):\n",
    "    for arquivo in arquivos:\n",
    "        if tipo in arquivo:\n",
    "            contador +=1 \n",
    "            caminho = os.path.join(raiz, arquivo)\n",
    "            nome, ext = os.path.splitext(arquivo)\n",
    "            tamanho = os.path.getsize(caminho)\n",
    "            tamanhoTotal += tamanho\n",
    "                                \n",
    "            if tamanho > 0:\n",
    "                print()\n",
    "                print('Arquivo encontrado: ', arquivo)\n",
    "                print('Caminho: ', caminho)\n",
    "                print('Nome: ', nome)\n",
    "                print('Extensão: ', ext)\n",
    "                print('Tamanho: ', formatarTamanho(tamanho))\n",
    "\n",
    "print()\n",
    "print(f'{contador} arquivo(s) encontrado(s).' + 'Tamanho Total: ' + formatarTamanho(tamanhoTotal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de Conexão ao Mysql e criação do banco de dados que receberá os microdados dos anos de 2015 a 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando um database.\n",
    "\n",
    "conexao = pymysql.connect(\n",
    "    host = 'localhost',\n",
    "    user = 'root',\n",
    "    password = 'admin')\n",
    "\n",
    "cursor = conexao.cursor()\n",
    "\n",
    "try:\n",
    "    cursor.execute('CREATE DATABASE dbenem')\n",
    "    print('Banco de Dados dbenem criado com sucesso!')\n",
    "except:\n",
    "    print('Banco de Dados dbenem já existe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conectando ao Banco de Dados enemdb.\n",
    "\n",
    "cursor.execute(\"SHOW DATABASES\")\n",
    "print('Databases MySql:')\n",
    "for x in cursor:\n",
    "  print(x)\n",
    "\n",
    "\n",
    "cursor.connection.select_db('dbenem')\n",
    "print('')\n",
    "print('Conexão com o banco de dados dbenem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Criação Dataframes Iniciado - 2020-08-14 18:18:43.229565.\n\nCriação Dataframe do Enem 2015 iniciada - 2020-08-14 18:18:43.231544.\nDataframe enem2015 criado com sucesso - 2020-08-14 18:19:32.748865.\n\nCriação Dataframe do Enem 2016 iniciada- 2020-08-14 18:19:32.749860.\nDataframe enem2016 criado com sucesso - 2020-08-14 18:20:29.942338.\n\nCriação Dataframe do Enem 2017 iniciada - 2020-08-14 18:20:29.943333.\nDataframe enem2017 criado com sucesso - 2020-08-14 18:21:05.075237.\n\nCriação Dataframe do Enem 2018 iniciada - 2020-08-14 18:21:05.076234.\nDataframe enem2018 criado com sucesso - 2020-08-14 18:21:35.011080.\n\nCriação Dataframe do Enem 2019 iniciada - 2020-08-14 18:21:35.012076.\nDataframe enem2019 criado com sucesso - 2020-08-14 18:22:01.726288.\n\n\nDataframes criados com sucesso - 2020-08-14 18:22:01.726288.\n"
    }
   ],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "print(f'Criação Dataframes Iniciado - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "print(f'Criação Dataframe do Enem 2015 iniciada - {datetime.now()}.')\n",
    "enem2015 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', sep=\",\", inferschema='true', encoding = 'ISO-8859-1', ).load(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\MICRODADOS_ENEM_2015.csv')\n",
    "print(f'Dataframe enem2015 criado com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação Dataframe do Enem 2016 iniciada- {datetime.now()}.')\n",
    "enem2016 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', sep=\";\", inferschema='true', encoding = 'ISO-8859-1').load(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem_2016.csv')\n",
    "print(f'Dataframe enem2016 criado com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação Dataframe do Enem 2017 iniciada - {datetime.now()}.')\n",
    "enem2017 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', sep=\";\", inferschema='true', encoding = 'ISO-8859-1').load(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\MICRODADOS_ENEM_2017.csv')\n",
    "print(f'Dataframe enem2017 criado com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação Dataframe do Enem 2018 iniciada - {datetime.now()}.')\n",
    "enem2018 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', sep=\";\", inferschema='true', encoding = 'ISO-8859-1').load(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\MICRODADOS_ENEM_2018.csv')\n",
    "print(f'Dataframe enem2018 criado com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação Dataframe do Enem 2019 iniciada - {datetime.now()}.')\n",
    "enem2019 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', sep=\";\", inferschema='true', encoding = 'ISO-8859-1').load(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\MICRODADOS_ENEM_2019.csv')\n",
    "print(f'Dataframe enem2019 criado com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "print(f'Dataframes criados com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem para tabela mysql - 2020-08-14 18:24:30.703137.\n\n\nCriação da Tabela tb_enem2015 iniciada - 2020-08-14 18:24:30.703137.\nImportação do Dataframe enem2015 para a Tabela tb_enem2015 iniciada - 2020-08-14 18:24:30.703137.\nImportação para a Tabela tb_enem2015 com sucesso - 2020-08-14 18:54:14.514733.\n\nCriação da Tabela tb_enem2016 iniciada - 2020-08-14 18:54:14.516727.\nImportação do Dataframe enem2016 para a Tabela tb_enem2016 iniciada - 2020-08-14 18:54:14.516727.\nImportação para a Tabela tb_enem2016 com sucesso - 2020-08-14 19:30:42.159196.\n\nCriação da Tabela tb_enem2017 iniciada - 2020-08-14 19:30:42.160617.\nImportação do Dataframe enem2017 para a Tabela tb_enem2017 iniciada - 2020-08-14 19:30:42.161615.\nImportação para a Tabela tb_enem2017 com sucesso - 2020-08-14 19:53:11.265111.\n\nCriação da Tabela tb_enem2018 iniciada - 2020-08-14 19:53:11.266107.\nImportação do Dataframe enem2018 para a Tabela tb_enem2018 iniciada - 2020-08-14 19:53:11.266107.\nImportação para a Tabela tb_enem2018 com sucesso - 2020-08-14 20:12:35.305334.\n\nCriação da Tabela tb_enem2019 iniciada - 2020-08-14 20:12:35.305334.\nImportação do Dataframe enem2019 para a Tabela tb_enem2019 iniciada - 2020-08-14 20:12:35.305334.\nImportação para a Tabela tb_enem2019 com sucesso - 2020-08-14 20:28:48.675241.\n\n\nTabelas e Importações realizados com sucesso - 2020-08-14 20:28:48.676238.\n"
    }
   ],
   "source": [
    "#Importando dos Dataframes para tabelas no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem para tabela mysql - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "print(f'Criação da Tabela tb_enem2015 iniciada - {datetime.now()}.')\n",
    "print(f'Importação do Dataframe enem2015 para a Tabela tb_enem2015 iniciada - {datetime.now()}.')\n",
    "enem2015.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://localhost/dbenem?useTimezone=true&serverTimezone=UTC',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='tb_enem2015',\n",
    "    user='root', password='admin').mode('overwrite').save()\n",
    "print(f'Importação para a Tabela tb_enem2015 com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação da Tabela tb_enem2016 iniciada - {datetime.now()}.')\n",
    "print(f'Importação do Dataframe enem2016 para a Tabela tb_enem2016 iniciada - {datetime.now()}.')\n",
    "enem2016.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://localhost/dbenem?useTimezone=true&serverTimezone=UTC',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='tb_enem2016',\n",
    "    user='root', password='admin').mode('overwrite').save()  \n",
    "print(f'Importação para a Tabela tb_enem2016 com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação da Tabela tb_enem2017 iniciada - {datetime.now()}.')\n",
    "print(f'Importação do Dataframe enem2017 para a Tabela tb_enem2017 iniciada - {datetime.now()}.')\n",
    "enem2017.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://localhost/dbenem?useTimezone=true&serverTimezone=UTC',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='tb_enem2017',\n",
    "    user='root', password='admin').mode('overwrite').save()\n",
    "print(f'Importação para a Tabela tb_enem2017 com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação da Tabela tb_enem2018 iniciada - {datetime.now()}.')\n",
    "print(f'Importação do Dataframe enem2018 para a Tabela tb_enem2018 iniciada - {datetime.now()}.')\n",
    "enem2018.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://localhost/dbenem?useTimezone=true&serverTimezone=UTC',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='tb_enem2018',\n",
    "    user='root', password='admin').mode('overwrite').save()\n",
    "print(f'Importação para a Tabela tb_enem2018 com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print(f'Criação da Tabela tb_enem2019 iniciada - {datetime.now()}.')\n",
    "print(f'Importação do Dataframe enem2019 para a Tabela tb_enem2019 iniciada - {datetime.now()}.')\n",
    "enem2019.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://localhost/dbenem?useTimezone=true&serverTimezone=UTC',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='tb_enem2019',\n",
    "    user='root', password='admin').mode('overwrite').save()    \n",
    "print(f'Importação para a Tabela tb_enem2019 com sucesso - {datetime.now()}.')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "print(f'Tabelas e Importações realizados com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final Pós Graduação Big Data - Senac Rio - 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de importação das Bibliotecas utilizadas no durante todo o projeto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas utilizadas para manipulação dos dados das paginas Web.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import zipfile\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicação do diretório para download dos arquivos Inep-Enem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicação do diretório desejado para download dos arquivos. \n",
    "#No exemplo, estamos salvando no diretório: C:\\Users\\Ricardo\\Downloads\n",
    "\n",
    "diretorio = input('Digite o diretório desejado para salvar os arquivos: ')\n",
    "os.chdir(r'{}'.format(diretorio))\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apos indicar o diretorio desejado, como boa pratica, sugerimos a criação da pasta onde será salvos os arquivos.\n",
    "#No exemplo, estamos salvando na pasta: MicrodadosEnem.'''\n",
    "\n",
    "pasta = input('Após indicação do diretório {}, informe o nome da pasta desejada para salvar os arquivos baixados da pagina {}: '.format(diretorio, url))\n",
    "\n",
    "try:\n",
    "    os.mkdir(pasta)\n",
    "    print('Pasta {} criada com sucesso!'.format(pasta))\n",
    "except FileExistsError as e:\n",
    "    print(f'Pasta {pasta} já existe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicação do diretório onde será salvo os arquivos baixados da url.\n",
    "\n",
    "os.chdir(r'{}\\{}'.format(diretorio, pasta))\n",
    "print('Os arquivos serão salvos no seguinte diretorio:', format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de Web Scraping no site do Inep, buscando os microdados do Enem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação de uma variavel que receberá o endereço URL (Uniform Resource Locator ou Localizador Padrão de Recursos).\n",
    "\n",
    "url = 'http://inep.gov.br/microdados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da variável que receberá todos os dados correspondente a varíavel \"url\".\n",
    "\n",
    "page = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da variável \"soup\", do pacote BeatifulSoup, que apresenta a estutura HTML da pagina que será trabalhada.\n",
    "\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No loop \"for\" abaixo, o realizaremos o filtro das tags desejadas.\n",
    "\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = link.get('href')\n",
    "    name = link.string\n",
    "    \n",
    "    print(theLink)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No processo abaixo, realizaremos o filtro das linhas, cujo o o tipo do arquivo desejado é *.zip.\n",
    "\n",
    "nomeArquivo = []\n",
    "typeFile = '.zip'\n",
    "i = 0\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = str(link.get('href')).lower()\n",
    "    name = link.string\n",
    "    if 'enem'in theLink:\n",
    "        if theLink[-4:] == typeFile:\n",
    "            print(theLink)\n",
    "            print(type(theLink))\n",
    "            print(name)\n",
    "            print(type(name))\n",
    "            nomeArquivo.append(theLink[39:-4].replace('/','_'))\n",
    "            print(type(nomeArquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processo de download dos arquivos desejados e salvos na na pasta indicada.\n",
    "\n",
    "i = 0\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = str(link.get('href')).lower()\n",
    "    name = link.string\n",
    "    if 'enem'in theLink:\n",
    "        if theLink[-4:] == typeFile:\n",
    "            if name is None:\n",
    "                title = 'SemTítulo' + typeFile\n",
    "            else:\n",
    "                title = nomeArquivo[i] + typeFile\n",
    "                i +=1\n",
    "            try:\n",
    "                with open(os.getcwd() + '/' + title,'r') as fileExists:\n",
    "                    print('Arquivo ' + title + ' existente no diretório '+ os.getcwd() + ' - ' + str(datetime.now()))\n",
    "                    fileExists.close()\n",
    "            except FileNotFoundError:\n",
    "                print('Download Iniciado - {}: '.format(datetime.now()) + title)\n",
    "                docFile = open(os.getcwd() + '/' + title,'wb')\n",
    "                docFile.write(urllib.request.urlopen(theLink).read())\n",
    "                docFile.close()\n",
    "                print('Download Concluído em {}'.format(datetime.now()))\n",
    "print('Não há mais arquivos para download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação do tamanho dos arquivos baixados.\n",
    "\n",
    "print('Apresentação Arquivos Enem baixados no díretório: ' + os.getcwd())\n",
    "contador = 0\n",
    "tamanhoTotal = 0\n",
    "tipo = '.zip'\n",
    "\n",
    "def formatarTamanho(tamanho):\n",
    "    base = 1024\n",
    "    kilo = base\n",
    "    mega = base ** 2\n",
    "    giga = base ** 3\n",
    "    tera = base ** 4\n",
    "    \n",
    "    if tamanho < kilo:\n",
    "        tamanho = base\n",
    "        texto = 'B'\n",
    "    elif tamanho < mega:\n",
    "        tamanho /= kilo\n",
    "        texto = 'K'\n",
    "    elif tamanho < giga:\n",
    "        tamanho /= mega\n",
    "        texto = 'M'\n",
    "    else:\n",
    "        tamanho < tera\n",
    "        tamanho /= giga\n",
    "        texto = 'G'\n",
    "    tamanho = round(tamanho, 2)\n",
    "    return f'{tamanho} {texto}'\n",
    "\n",
    "for raiz, diretorios, arquivos in os.walk(os.getcwd()):\n",
    "    for arquivo in arquivos:\n",
    "        if tipo in arquivo:\n",
    "            contador +=1 \n",
    "            caminho = os.path.join(raiz, arquivo)\n",
    "            nome, ext = os.path.splitext(arquivo)\n",
    "            tamanho = os.path.getsize(caminho)\n",
    "            tamanhoTotal += tamanho\n",
    "                                \n",
    "            if tamanho > 0:\n",
    "                print()\n",
    "                print('Arquivo encotrado: ', arquivo)\n",
    "                print('Caminho: ', caminho)\n",
    "                print('Nome: ', nome)\n",
    "                print('Extensão: ', ext)\n",
    "                print('Tamanho: ', formatarTamanho(tamanho))\n",
    "\n",
    "print()\n",
    "print(f'{contador} arquivo(s) encontrado(s).' + 'Tamanho Total: ' + formatarTamanho(tamanhoTotal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de Conexão ao Mysql e criação do banco de dados que receberá os microdados dos anos de 2015 a 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Banco de Dados enemdb já existe!\n"
    }
   ],
   "source": [
    "# Criando um database.\n",
    "\n",
    "conexao = pymysql.connect(\n",
    "    host = 'localhost',\n",
    "    user = 'root',\n",
    "    password = 'admin')\n",
    "\n",
    "cursor = conexao.cursor()\n",
    "\n",
    "try:\n",
    "    cursor.execute('CREATE DATABASE enemdb')\n",
    "    print('Banco de Dados enemdb criado com sucesso!')\n",
    "except:\n",
    "    print('Banco de Dados enemdb já existe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Databases MySql:\n('enemdb',)\n('information_schema',)\n('mysql',)\n('performance_schema',)\n('sakila',)\n('sys',)\n('world',)\n\nConexão com o banco de dados enemdb\n"
    }
   ],
   "source": [
    "# Conectando ao Banco de Dados enemdb.\n",
    "\n",
    "cursor.execute(\"SHOW DATABASES\")\n",
    "print('Databases MySql:')\n",
    "for x in cursor:\n",
    "  print(x)\n",
    "\n",
    "\n",
    "cursor.connection.select_db('enemdb')\n",
    "print('')\n",
    "print('Conexão com o banco de dados enemdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:admin@localhost/enemdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após download dos microdados, necessitamos descompactar os arquivos zipados, explorar a estrutura dos mesmos, buscando os microdados necessários para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['DADOS/',\n 'DADOS/CONSISTENCIA_ENEM_ESCOLA_2015.CSV',\n 'DADOS/MICRODADOS_ENEM_2015.csv',\n 'DICION╡RIO/',\n 'DICION╡RIO/Dicionário_Microdados_Enem_2015.ods',\n 'DICION╡RIO/Dicionário_Microdados_Enem_2015.xlsx',\n 'INPUTS/',\n 'INPUTS/INPUT_ SPSS_MICRODADOS_ENEM_2015.sps',\n 'INPUTS/INPUT_SAS_CONSISTENCIA_ENEM_ESCOLA_2015.sas',\n 'INPUTS/INPUT_SAS_MICRODADOS_ENEM_2015.sas',\n 'INPUTS/INPUT_SPSS_CONSISTENCIA_ENEM_ESCOLA_2015.sps',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/edital_enem_2015_dou.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/Leia_Me_Enem_2015.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/Matriz_Referencia_Enem.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/Nota_explicativa_enem2015_por_escola.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/Portaria_Inep_ENEM_por_Escola_2015.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/Thumbs.db',\n 'PLANILHAS/',\n 'PLANILHAS/ITENS_ENEM_2015.ods',\n 'PLANILHAS/ITENS_ENEM_2015.xlsx',\n 'PLANILHAS/PLANILHA_ENEM_ESCOLA_2015 - Site.xlsx',\n 'PLANILHAS/PLANILHA_ENEM_ESCOLA_2015.ods',\n 'PLANILHAS/PLANILHA_ENEM_ESCOLA_2015.xlsx',\n 'PLANILHAS/Sistema_Enem_2015_terceira_divulgaç╞o_para_validaç╞o.xlsm',\n 'PROVAS e GABARITOS/',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno1_Azul_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno2_Amarelo_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno3_Branco_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno4_Rosa_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno5_Amarelo_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno6_Cinza_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno7_Azul_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Caderno8_Rosa_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno1_Azul_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno2_Amarelo_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno3_Branco_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno4_Rosa_Sab.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno5_Amarelo_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno6_Cinza_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno7_Azul_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Gab_Caderno8_Rosa_Dom.pdf',\n 'PROVAS e GABARITOS/PRIMEIRA APLICAÇ╟O/Thumbs.db',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno1_Azul_Sab_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno2_Amarelo_Sab_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno3_Branco_Sab_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno4_Rosa_Sab_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno5_Amarelo_Dom_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno6_Cinza_Dom_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno7_Azul_Dom_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Caderno8_Rosa_Dom_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Gab_Dom_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Gab_Sab_2.pdf.pdf',\n 'PROVAS e GABARITOS/SEGUNDA APLICAÇ╟O/Thumbs.db',\n 'PROVAS e GABARITOS/Thumbs.db']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2015 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2015.zip', mode = 'r')\n",
    "enemzip2015.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Criação Dataframe Enem - 2020-07-15 18:09:00.877747.\nDataframe criado com sucesso - 2020-07-15 18:09:01.112978.\n"
    }
   ],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "print(f'Criação Dataframe Enem - {datetime.now()}.')\n",
    "\n",
    "with enemzip2015.open('DADOS/MICRODADOS_ENEM_2015.csv') as enem2015:\n",
    "    df_enem2015 = pd.read_csv(enem2015, sep = ',', encoding= 'ISO-8859-1', nrows = 0)\n",
    "print(f'Dataframe criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['NU_INSCRICAO', 'NU_ANO', 'CO_MUNICIPIO_RESIDENCIA',\n       'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA',\n       'IN_ESTUDA_CLASSE_HOSPITALAR', 'IN_TREINEIRO', 'CO_ESCOLA',\n       'CO_MUNICIPIO_ESC', 'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC',\n       'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC',\n       'NU_IDADE', 'TP_SEXO', 'TP_NACIONALIDADE',\n       'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO',\n       'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ST_CONCLUSAO',\n       'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'TP_ESTADO_CIVIL',\n       'TP_COR_RACA', 'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ',\n       'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA',\n       'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL',\n       'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_GESTANTE', 'IN_LACTANTE',\n       'IN_IDOSO', 'IN_DISCALCULIA', 'IN_AUTISMO', 'IN_VISAO_MONOCULAR',\n       'IN_SABATISTA', 'IN_OUTRA_DEF', 'IN_SEM_RECURSO', 'IN_NOME_SOCIAL',\n       'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR',\n       'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS', 'IN_LEITURA_LABIAL',\n       'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA',\n       'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE', 'IN_MACA', 'IN_COMPUTADOR',\n       'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO',\n       'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO',\n       'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE',\n       'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA',\n       'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL',\n       'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO',\n       'IN_MATERIAL_ESPECÍFICO', 'IN_CERTIFICADO',\n       'NO_ENTIDADE_CERTIFICACAO', 'CO_UF_ENTIDADE_CERTIFICACAO',\n       'SG_UF_ENTIDADE_CERTIFICACAO', 'CO_MUNICIPIO_PROVA',\n       'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',\n       'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC',\n       'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n       'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC',\n       'NU_NOTA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH',\n       'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TP_LINGUA',\n       'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC',\n       'TX_GABARITO_MT', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1',\n       'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5',\n       'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006',\n       'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n       'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022',\n       'Q023', 'Q024', 'Q025', 'Q026', 'Q027', 'Q028', 'Q029', 'Q030',\n       'Q031', 'Q032', 'Q033', 'Q034', 'Q035', 'Q036', 'Q037', 'Q038',\n       'Q039', 'Q040', 'Q041', 'Q042', 'Q043', 'Q044', 'Q045', 'Q046',\n       'Q047', 'Q048', 'Q049', 'Q050'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2015.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2015 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2015.open('DADOS/MICRODADOS_ENEM_2015.csv') as enem2015:\n",
    "    df_enem2015_completo = pd.read_csv(enem2015, sep = ',', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2015_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2015_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2015 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2015_completo.to_sql(\n",
    "    name = 'tb_enem2015',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2015 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2015_completo)\n",
    "    del(df_enem2015)\n",
    "    del(enem2015)\n",
    "    del(enemzip2015)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2016 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2016.zip', mode = 'r')\n",
    "enemzip2016.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2016.open('Microdados_enem_2016/DADOS/microdados_enem_2016.csv') as enem2016:\n",
    "    df_enem2016 = pd.read_csv(enem2016, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2016.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2016 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2016.open('Microdados_enem_2016/DADOS/microdados_enem_2016.csv') as enem2016:\n",
    "    df_enem2016_completo = pd.read_csv(enem2016, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2016_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enem2016_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2016 para tabela mysql - {datetime.now()}.')\n",
    "df_enem2016_completo.to_sql(\n",
    "    name = 'tb_enem2016',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2016 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del(df_enem2016_completo)\n",
    "    del(df_enem2016)\n",
    "    del(enem2016)\n",
    "    del(enemzip2016)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2017 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2017.zip', mode = 'r')\n",
    "enemzip2017.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2017.open('Microdados Enem 2017/DADOS/MICRODADOS_ENEM_2017.csv') as enem2017:\n",
    "    df_enem2017 = pd.read_csv(enem2017, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2017.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2017 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2017.open('Microdados Enem 2017/DADOS/MICRODADOS_ENEM_2017.csv') as enem2017:\n",
    "    df_enem2017_completo = pd.read_csv(enem2017, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2017_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2017_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2017 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2017_completo.to_sql(\n",
    "    name = 'tb_enem2017',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2017 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2017_completo)\n",
    "    del(df_enem2017)\n",
    "    del(enem2017)\n",
    "    del(enemzip2017)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2018 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2018.zip', mode = 'r')\n",
    "enemzip2018.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2018.open('DADOS/MICRODADOS_ENEM_2018.csv') as enem2018:\n",
    "    df_enem2018 = pd.read_csv(enem2018, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2018.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2018 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2018.open('DADOS/MICRODADOS_ENEM_2018.csv') as enem2018:\n",
    "    df_enem2018_completo = pd.read_csv(enem2018, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2018_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2018_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2018 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2018_completo.to_sql(\n",
    "    name = 'tb_enem2018',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2018 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2018_completo)\n",
    "    del(df_enem2018)\n",
    "    del(enem2018)\n",
    "    del(enemzip2018)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2019 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem_2019.zip', mode = 'r')\n",
    "enemzip2019.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2019.open('DADOS/MICRODADOS_ENEM_2019.csv') as enem2019:\n",
    "    df_enem2019 = pd.read_csv(enem2019, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2019.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2019 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2019.open('DADOS/MICRODADOS_ENEM_2019.csv') as enem2019:\n",
    "    df_enem2019_completo = pd.read_csv(enem2019, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2019_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2019_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2019 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2019_completo.to_sql(\n",
    "    name = 'tb_enem2019',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2019 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2019_completo)\n",
    "    del(df_enem2019)\n",
    "    del(enem2019)\n",
    "    del(enemzip2019)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de importação dos dados necessários para composição de um Dataframe e apresentação dos resultados da analise e plotagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação dos dataframes relativos aos dicionarios levantados dos microdados Enem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_BINARIO.json', 'r', encoding='utf-8') as BINARIO:\n",
    "    dic_BINARIO = json.load(BINARIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_Q001_Q002.json', 'r', encoding='utf-8') as Q001_Q002:\n",
    "    dic_Q001_Q002 = json.load(Q001_Q002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_Q006.json', 'r', encoding='utf-8') as Q006:\n",
    "    dic_Q006 = json.load(Q006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_Q022.json', 'r', encoding='utf-8') as Q022:\n",
    "    dic_Q022 = json.load(Q022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_Q024.json', 'r', encoding='utf-8') as Q024:\n",
    "    dic_Q024 = json.load(Q024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_Q025.json', 'r', encoding='utf-8') as Q025:\n",
    "    dic_Q025 = json.load(Q025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_COR_RACA.json', 'r', encoding='utf-8') as TP_COR_RACA:\n",
    "    dic_TP_COR_RACA = json.load(TP_COR_RACA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_ESTADO_CIVIL.json', 'r', encoding='utf-8') as TP_ESTADO_CIVIL:\n",
    "    dic_TP_ESTADO_CIVIL = json.load(TP_ESTADO_CIVIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_LINGUA.json', 'r', encoding='utf-8') as TP_LINGUA:\n",
    "    dic_TP_LINGUA = json.load(TP_LINGUA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_NACIONALIDADE.json', 'r', encoding='utf-8') as TP_NACIONALIDADE:\n",
    "    dic_TP_NACIONALIDADE = json.load(TP_NACIONALIDADE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_PRESENCA.json', 'r', encoding='utf-8') as TP_PRESENCA:\n",
    "    dic_TP_PRESENCA = json.load(TP_PRESENCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_SEXO.json', 'r', encoding='utf-8') as TP_SEXO:\n",
    "    dic_TP_SEXO = json.load(TP_SEXO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\Dicionários\\dic_TP_ST_CONCLUSAO.json', 'r', encoding='utf-8') as TP_ST_CONCLUSAO:\n",
    "    dic_TP_ST_CONCLUSAO = json.load(TP_ST_CONCLUSAO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do Dataframe para realização da análise exploratória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após análise, verificamos quais serão as colunas selecionadas e criamos a lista das colunas importadas para\n",
    "# o dataframe do Enem.\n",
    "\n",
    "colunas2015 = [\n",
    "    'NU_INSCRICAO', \n",
    "    'NU_ANO',  \n",
    "    'NO_MUNICIPIO_RESIDENCIA', \n",
    "    'SG_UF_RESIDENCIA', \n",
    "    'IN_TREINEIRO', \n",
    "    'NU_IDADE', \n",
    "    'TP_SEXO', \n",
    "    'TP_NACIONALIDADE',\n",
    "    'NO_MUNICIPIO_NASCIMENTO',\n",
    "    'SG_UF_NASCIMENTO', \n",
    "    'TP_ST_CONCLUSAO',\n",
    "    'TP_ESTADO_CIVIL',\n",
    "    'TP_COR_RACA', \n",
    "    'IN_BAIXA_VISAO', \n",
    "    'IN_CEGUEIRA', \n",
    "    'IN_SURDEZ',\n",
    "    'IN_DEFICIENCIA_AUDITIVA', \n",
    "    'IN_SURDO_CEGUEIRA',\n",
    "    'IN_DEFICIENCIA_FISICA', \n",
    "    'IN_DEFICIENCIA_MENTAL',\n",
    "    'IN_DEFICIT_ATENCAO', \n",
    "    'IN_DISLEXIA', \n",
    "    'IN_GESTANTE', \n",
    "    'IN_LACTANTE',\n",
    "    'IN_IDOSO', \n",
    "    'IN_DISCALCULIA', \n",
    "    'IN_AUTISMO', \n",
    "    'IN_VISAO_MONOCULAR',\n",
    "    'IN_OUTRA_DEF', \n",
    "    'NO_MUNICIPIO_PROVA', \n",
    "    'SG_UF_PROVA',\n",
    "    'TP_PRESENCA_CN', \n",
    "    'TP_PRESENCA_CH', \n",
    "    'TP_PRESENCA_LC',\n",
    "    'TP_PRESENCA_MT', \n",
    "    'NU_NOTA_CN', \n",
    "    'NU_NOTA_CH', \n",
    "    'NU_NOTA_LC',\n",
    "    'NU_NOTA_MT', \n",
    "    'TP_LINGUA',\n",
    "    'TP_STATUS_REDACAO', \n",
    "    'NU_NOTA_REDACAO', \n",
    "    'Q001', \n",
    "    'Q002', \n",
    "    'Q005', \n",
    "    'Q006',\n",
    "    'Q022',\n",
    "    'Q024', \n",
    "    'Q025',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criação do Dataframe df_enem2015 através da importação da tabela tb_enem2015 oriundo do MySql.\n",
    "\n",
    "print(f'Dataframe df_enem2015 sendo criado - {datetime.now()}.')\n",
    "\n",
    "df_enem2015 = pd.DataFrame(engine.execute('SELECT NU_INSCRICAO, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA, NU_IDADE, TP_SEXO, TP_NACIONALIDADE, TP_ST_CONCLUSAO, TP_ESTADO_CIVIL, TP_COR_RACA FROM tb_enem2015'), dtype = str)\n",
    "\n",
    "print(f'Dataframe df_enem2015 criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Apresentaçao das primeiras inforamções do Dataframe criado.\n",
    "\n",
    "df_enem2015.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação das cinco primeiras linhas do dataframe.\n",
    "\n",
    "df_enem2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclusão dos nomes das colunas, afim de ajudar na leitura dos dados.\n",
    "\n",
    "df_enem2015.columns = ['NU_INSCRICAO', 'NO_MUNICIPIO_RESIDENCIA', 'SG_UF_RESIDENCIA', 'NU_IDADE', 'TP_SEXO', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação das cinco primeiras linhas do dataframe com os nomes das colunas.\n",
    "\n",
    "df_enem2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Criação da coluna SEXO, com apoio do dicionário. \n",
    "\n",
    "print(f'Inclusão da coluna SEXO no Dataframe inciada - {datetime.now()}.')\n",
    "\n",
    "df_enem2015['SEXO'] = [dic_TP_SEXO[s] for s in df_enem2015.TP_SEXO]\n",
    "\n",
    "print(f'Coluna SEXO criada com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Criação da coluna NACIONALIDADE, com apoio do dicionário. \n",
    "\n",
    "print(f'Inclusão da coluna NACIONALIDADE no Dataframe inciada - {datetime.now()}.')\n",
    "\n",
    "df_enem2015['NACIONALIDADE'] = [dic_TP_NACIONALIDADE[n] for n in df_enem2015.TP_NACIONALIDADE]\n",
    "\n",
    "print(f'Coluna NACIONALIDADE criada com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Criação da coluna STATUS_CONCLUSAO, com apoio do dicionário. \n",
    "\n",
    "print(f'Inclusão da coluna STATUS_CONCLUSAO no Dataframe inciada - {datetime.now()}.')\n",
    "\n",
    "df_enem2015['STATUS_CONCLUSAO'] = [dic_TP_ST_CONCLUSAO[c] for c in df_enem2015.TP_ST_CONCLUSAO]\n",
    "\n",
    "print(f'Coluna STATUS_CONCLUSAO criada com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enem2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação do Raking dos Estados da Federação por nº de Inscrição. \n",
    "\n",
    "df_enem2015.filter(items= ['NU_INSCRICAO', 'SG_UF_RESIDENCIA']).groupby('SG_UF_RESIDENCIA').count().sort_values(by = 'NU_INSCRICAO', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação do Raking do Sexo por nº de Inscrição. \n",
    "\n",
    "df_enem2015.filter(items= ['NU_INSCRICAO', 'SEXO']).groupby('SEXO').count().sort_values(by = 'NU_INSCRICAO', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação do Raking das faixas etárias por nº de Inscrição. \n",
    "\n",
    "df_enem2015_idadedf_enem2015.filter(items= ['NU_INSCRICAO', 'NU_IDADE']).groupby('NU_IDADE').count().sort_values(by = 'NU_INSCRICAO', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação do Raking das Nacionalidades por nº de inscrição.\n",
    "\n",
    "df_enem2015.filter(items= ['NU_INSCRICAO', 'NACIONALIDADE']).groupby('NACIONALIDADE').count().sort_values(by = 'NU_INSCRICAO', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594847128256",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
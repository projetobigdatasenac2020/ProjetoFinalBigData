{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final Pós Graduação Big Data - Senac Rio - 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de importação das Bibliotecas utilizadas no durante todo o projeto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas utilizadas para manipulação dos dados das paginas Web.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import zipfile\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicação do diretório para download dos arquivos Inep-Enem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicação do diretório desejado para download dos arquivos. \n",
    "#No exemplo, estamos salvando no diretório: C:\\Users\\Ricardo\\Downloads\n",
    "\n",
    "diretorio = input('Digite o diretório desejado para salvar os arquivos: ')\n",
    "os.chdir(r'{}'.format(diretorio))\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apos indicar o diretorio desejado, como boa pratica, sugerimos a criação da pasta onde será salvos os arquivos.\n",
    "#No exemplo, estamos salvando na pasta: MicrodadosEnem.'''\n",
    "\n",
    "pasta = input('Após indicação do diretório {}, informe o nome da pasta desejada para salvar os arquivos baixados da pagina {}: '.format(diretorio, url))\n",
    "\n",
    "try:\n",
    "    os.mkdir(pasta)\n",
    "    print('Pasta {} criada com sucesso!'.format(pasta))\n",
    "except FileExistsError as e:\n",
    "    print(f'Pasta {pasta} já existe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicação do diretório onde será salvo os arquivos baixados da url.\n",
    "\n",
    "os.chdir(r'{}\\{}'.format(diretorio, pasta))\n",
    "print('Os arquivos serão salvos no seguinte diretorio:', format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de Web Scraping no site do Inep, buscando os microdados do Enem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação de uma variavel que receberá o endereço URL (Uniform Resource Locator ou Localizador Padrão de Recursos).\n",
    "\n",
    "url = 'http://inep.gov.br/microdados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da variável que receberá todos os dados correspondente a varíavel \"url\".\n",
    "\n",
    "page = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da variável \"soup\", do pacote BeatifulSoup, que apresenta a estutura HTML da pagina que será trabalhada.\n",
    "\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No loop \"for\" abaixo, o realizaremos o filtro das tags desejadas.\n",
    "\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = link.get('href')\n",
    "    name = link.string\n",
    "    \n",
    "    print(theLink)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No processo abaixo, realizaremos o filtro das linhas, cujo o o tipo do arquivo desejado é *.zip.\n",
    "\n",
    "nomeArquivo = []\n",
    "typeFile = '.zip'\n",
    "i = 0\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = str(link.get('href')).lower()\n",
    "    name = link.string\n",
    "    if 'enem'in theLink:\n",
    "        if theLink[-4:] == typeFile:\n",
    "            print(theLink)\n",
    "            print(type(theLink))\n",
    "            print(name)\n",
    "            print(type(name))\n",
    "            nomeArquivo.append(theLink[39:-4].replace('/','_'))\n",
    "            print(type(nomeArquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processo de download dos arquivos desejados e salvos na na pasta indicada.\n",
    "\n",
    "i = 0\n",
    "for link in soup.findAll('a'):\n",
    "    theLink = str(link.get('href')).lower()\n",
    "    name = link.string\n",
    "    if 'enem'in theLink:\n",
    "        if theLink[-4:] == typeFile:\n",
    "            if name is None:\n",
    "                title = 'SemTítulo' + typeFile\n",
    "            else:\n",
    "                title = nomeArquivo[i] + typeFile\n",
    "                i +=1\n",
    "            try:\n",
    "                with open(os.getcwd() + '/' + title,'r') as fileExists:\n",
    "                    print('Arquivo ' + title + ' existente no diretório '+ os.getcwd() + ' - ' + str(datetime.now()))\n",
    "                    fileExists.close()\n",
    "            except FileNotFoundError:\n",
    "                print('Download Iniciado - {}: '.format(datetime.now()) + title)\n",
    "                docFile = open(os.getcwd() + '/' + title,'wb')\n",
    "                docFile.write(urllib.request.urlopen(theLink).read())\n",
    "                docFile.close()\n",
    "                print('Download Concluído em {}'.format(datetime.now()))\n",
    "print('Não há mais arquivos para download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação do tamanho dos arquivos baixados.\n",
    "\n",
    "print('Apresentação Arquivos Enem baixados no díretório: ' + os.getcwd())\n",
    "contador = 0\n",
    "tamanhoTotal = 0\n",
    "tipo = '.zip'\n",
    "\n",
    "def formatarTamanho(tamanho):\n",
    "    base = 1024\n",
    "    kilo = base\n",
    "    mega = base ** 2\n",
    "    giga = base ** 3\n",
    "    tera = base ** 4\n",
    "    \n",
    "    if tamanho < kilo:\n",
    "        tamanho = base\n",
    "        texto = 'B'\n",
    "    elif tamanho < mega:\n",
    "        tamanho /= kilo\n",
    "        texto = 'K'\n",
    "    elif tamanho < giga:\n",
    "        tamanho /= mega\n",
    "        texto = 'M'\n",
    "    else:\n",
    "        tamanho < tera\n",
    "        tamanho /= giga\n",
    "        texto = 'G'\n",
    "    tamanho = round(tamanho, 2)\n",
    "    return f'{tamanho} {texto}'\n",
    "\n",
    "for raiz, diretorios, arquivos in os.walk(os.getcwd()):\n",
    "    for arquivo in arquivos:\n",
    "        if tipo in arquivo:\n",
    "            contador +=1 \n",
    "            caminho = os.path.join(raiz, arquivo)\n",
    "            nome, ext = os.path.splitext(arquivo)\n",
    "            tamanho = os.path.getsize(caminho)\n",
    "            tamanhoTotal += tamanho\n",
    "                                \n",
    "            if tamanho > 0:\n",
    "                print()\n",
    "                print('Arquivo encotrado: ', arquivo)\n",
    "                print('Caminho: ', caminho)\n",
    "                print('Nome: ', nome)\n",
    "                print('Extensão: ', ext)\n",
    "                print('Tamanho: ', formatarTamanho(tamanho))\n",
    "\n",
    "print()\n",
    "print(f'{contador} arquivo(s) encontrado(s).' + 'Tamanho Total: ' + formatarTamanho(tamanhoTotal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de Conexão ao Mysql e criação do banco de dados que receberá os microdados dos anos de 2015 a 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Banco de Dados enemdb já existe!\n"
    }
   ],
   "source": [
    "# Criando um database.\n",
    "\n",
    "conexao = pymysql.connect(\n",
    "    host = 'localhost',\n",
    "    user = 'root',\n",
    "    password = 'admin')\n",
    "\n",
    "cursor = conexao.cursor()\n",
    "\n",
    "try:\n",
    "    cursor.execute('CREATE DATABASE enemdb')\n",
    "    print('Banco de Dados enemdb criado com sucesso!')\n",
    "except:\n",
    "    print('Banco de Dados enemdb já existe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Databases MySql:\n('enemdb',)\n('information_schema',)\n('mysql',)\n('performance_schema',)\n('sakila',)\n('sys',)\n('world',)\n\nConexão com o banco de dados enemdb\n"
    }
   ],
   "source": [
    "# Conectando ao Banco de Dados enemdb.\n",
    "\n",
    "cursor.execute(\"SHOW DATABASES\")\n",
    "print('Databases MySql:')\n",
    "for x in cursor:\n",
    "  print(x)\n",
    "\n",
    "\n",
    "cursor.connection.select_db('enemdb')\n",
    "print('')\n",
    "print('Conexão com o banco de dados enemdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:admin@localhost/enemdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após download dos microdados, necessitamos descompactar os arquivos zipados, explorar a estrutura dos mesmos, buscando os microdados necessários para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2015 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2015.zip', mode = 'r')\n",
    "enemzip2015.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2015.open('DADOS/MICRODADOS_ENEM_2015.csv') as enem2015:\n",
    "    df_enem2015 = pd.read_csv(enem2015, sep = ',', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2015.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2015 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2015.open('DADOS/MICRODADOS_ENEM_2015.csv') as enem2015:\n",
    "    df_enem2015_completo = pd.read_csv(enem2015, sep = ',', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2015_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2015_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2015 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2015_completo.to_sql(\n",
    "    name = 'tb_enem2015',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 500000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2015 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2015_completo)\n",
    "    del(df_enem2015)\n",
    "    del(enem2015)\n",
    "    del(enemzip2015)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2016 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2016.zip', mode = 'r')\n",
    "enemzip2016.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2016.open('Microdados_enem_2016/DADOS/microdados_enem_2016.csv') as enem2016:\n",
    "    df_enem2016 = pd.read_csv(enem2016, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2016.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2016 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2016.open('Microdados_enem_2016/DADOS/microdados_enem_2016.csv') as enem2016:\n",
    "    df_enem2016_completo = pd.read_csv(enem2016, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2016_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enem2016_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2016 para tabela mysql - {datetime.now()}.')\n",
    "df_enem2016_completo.to_sql(\n",
    "    name = 'tb_enem2016',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2016 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del(df_enem2016_completo)\n",
    "    del(df_enem2016)\n",
    "    del(enem2016)\n",
    "    del(enemzip2016)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Microdados Enem 2017/',\n 'Microdados Enem 2017/DADOS/',\n 'Microdados Enem 2017/DADOS/ITENS_PROVA_2017.csv',\n 'Microdados Enem 2017/DADOS/MICRODADOS_ENEM_2017.csv',\n 'Microdados Enem 2017/DICION╡RIO/',\n 'Microdados Enem 2017/DICION╡RIO/Dicionário_Microdados_Enem_2017.ods',\n 'Microdados Enem 2017/DICION╡RIO/Dicionário_Microdados_Enem_2017.xlsx',\n 'Microdados Enem 2017/DICION╡RIO/~$Dicionário_Microdados_Enem_2017.xlsx',\n 'Microdados Enem 2017/INPUTS/',\n 'Microdados Enem 2017/INPUTS/INPUT_ SPSS_MICRODADOS_ENEM_2017.sps',\n 'Microdados Enem 2017/INPUTS/INPUT_R_ITENS_PROVA_2017.R',\n 'Microdados Enem 2017/INPUTS/INPUT_R_MICRODADOS_ENEM_2017.R',\n 'Microdados Enem 2017/INPUTS/INPUT_SAS_ITENS_PROVA_2017.sas',\n 'Microdados Enem 2017/INPUTS/INPUT_SAS_MICRODADOS_ENEM_2017.sas',\n 'Microdados Enem 2017/INPUTS/INPUT_SPSS_ITENS_PROVA_2017.sps',\n 'Microdados Enem 2017/LEIA-ME e DOCUMENTOS TÉCNICOS/',\n 'Microdados Enem 2017/LEIA-ME e DOCUMENTOS TÉCNICOS/Edital_enem_2017.pdf',\n 'Microdados Enem 2017/LEIA-ME e DOCUMENTOS TÉCNICOS/Leia_Me_Enem_2017.pdf',\n 'Microdados Enem 2017/LEIA-ME e DOCUMENTOS TÉCNICOS/Manual_de_redacao_do_enem_2017.pdf',\n 'Microdados Enem 2017/LEIA-ME e DOCUMENTOS TÉCNICOS/Matriz_referencia_enem.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_01_DIA_1_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_02_DIA_1_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_03_DIA_1_BRANCO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_04_DIA_1_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_05_DIA_2_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_05_DIA_2_AMARELO_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_05_DIA_2_AMARELO_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_06_DIA_2_CINZA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_07_DIA_2_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_08_DIA_2_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_09_DIA_1_LARANJA_LEDOR.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_10_DIA_1_VERDE_LIBRAS.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_11_DIA_2_LARANJA_LEDOR.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P1_GAB_12_DIA_2_VERDE_LIBRAS.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_02_DIA_1_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_03_DIA_1_BRANCO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_04_DIA_1_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_05_DIA_2_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_05_DIA_2_AMARELO_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_05_DIA_2_AMARELO_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_06_DIA_2_CINZA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_07_DIA_2_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/GABARITOS/ENEM_2017_P2_GAB_08_DIA_2_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_01_DIA_1_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_02_DIA_1_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_03_DIA_1_BRANCO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_04_DIA_1_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_09_DIA_1_LARANJA_LEDOR.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/ENEM_2017_P1_CAD_10_DIA_1_VERDE_LIBRAS.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/01_Domingo 05-11-17/Thumbs.db',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_05_DIA_2_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_05_DIA_2_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_05_DIA_2_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_06_DIA_2_CINZA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_07_DIA_2_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_08_DIA_2_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_11_DIA_2_LARANJA_LEDOR.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/ENEM_2017_P1_CAD_12_DIA_2_VERDE_LIBRAS.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P1/02_Domingo 12-11-17/Thumbs.db',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/ENEM_2017_P2_CAD_01_DIA_1_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/ENEM_2017_P2_CAD_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/ENEM_2017_P2_CAD_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/ENEM_2017_P2_CAD_02_DIA_1_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/ENEM_2017_P2_CAD_03_DIA_1_BRANCO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/ENEM_2017_P2_CAD_04_DIA_1_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 01/Thumbs.db',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/ENEM_2017_P2_CAD_05_DIA_2_AMARELO.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/ENEM_2017_P2_CAD_05_DIA_2_AMARELO_AMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/ENEM_2017_P2_CAD_05_DIA_2_AMARELO_SUPERAMPLIADA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/ENEM_2017_P2_CAD_06_DIA_2_CINZA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/ENEM_2017_P2_CAD_07_DIA_2_AZUL.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/ENEM_2017_P2_CAD_08_DIA_2_ROSA.pdf',\n 'Microdados Enem 2017/PROVAS E GABARITOS/PROVAS/P2/Dia 02/Thumbs.db']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2017 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2017.zip', mode = 'r')\n",
    "enemzip2017.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2017.open('Microdados Enem 2017/DADOS/MICRODADOS_ENEM_2017.csv') as enem2017:\n",
    "    df_enem2017 = pd.read_csv(enem2017, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['NU_INSCRICAO', 'NU_ANO', 'CO_MUNICIPIO_RESIDENCIA',\n       'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA',\n       'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n       'TP_NACIONALIDADE', 'CO_MUNICIPIO_NASCIMENTO',\n       'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO',\n       'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n       'IN_TREINEIRO', 'CO_ESCOLA', 'CO_MUNICIPIO_ESC',\n       'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC',\n       'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC',\n       'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ',\n       'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA',\n       'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL',\n       'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA',\n       'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE',\n       'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR',\n       'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18',\n       'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS',\n       'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS',\n       'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE',\n       'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO',\n       'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO',\n       'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE',\n       'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA',\n       'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL',\n       'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO',\n       'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'CO_MUNICIPIO_PROVA',\n       'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',\n       'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC',\n       'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n       'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC',\n       'NU_NOTA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH',\n       'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TP_LINGUA',\n       'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC',\n       'TX_GABARITO_MT', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1',\n       'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5',\n       'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006',\n       'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n       'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022',\n       'Q023', 'Q024', 'Q025', 'Q026', 'Q027'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2017.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem 2017 para o Dataframe - 2020-07-11 18:29:31.269977.\nDataframe df_enem2017_completo criado com sucesso - 2020-07-11 18:32:47.963056.\n"
    }
   ],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2017 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2017.open('Microdados Enem 2017/DADOS/MICRODADOS_ENEM_2017.csv') as enem2017:\n",
    "    df_enem2017_completo = pd.read_csv(enem2017, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2017_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6731341 entries, 0 to 6731340\nColumns: 137 entries, NU_INSCRICAO to Q027\ndtypes: float64(31), int64(63), object(43)\nmemory usage: 6.9+ GB\n"
    }
   ],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2017_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem 2017 para tabela mysql - 2020-07-11 18:32:48.498032.\nTabela tb_enem2017 criada com sucesso - 2020-07-11 19:33:53.562896\nDados importados com sucesso para a tabela tb_enem2017\n"
    }
   ],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2017 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2017_completo.to_sql(\n",
    "    name = 'tb_enem2017',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2017 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Objetos deletados com sucesso - Memória liberada.\n"
    }
   ],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2017_completo)\n",
    "    del(df_enem2017)\n",
    "    del(enem2017)\n",
    "    del(enemzip2017)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['LEIA-ME e DOCUMENTOS TÉCNICOS/',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/edital_enem_2018.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/matriz_referencia.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/manual_de_redacao_do_enem_2018.pdf',\n 'LEIA-ME e DOCUMENTOS TÉCNICOS/Leia_Me_Enem_2018.pdf',\n 'PLANILHAS_TS_ITEM/',\n 'PROVAS E GABARITOS/',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_09_DIA_1_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_10_DIA_1_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_11_DIA_2_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_12_DIA_2_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_05_DIA_2_SUPERAMPLIADA.pdf.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_09_DIA_1_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_05_DIA_2_AMARELO.pdf.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_12_DIA_2_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_11_DIA_2_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_CAD_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_10_DIA_1_VERDE_LIBRAS.pdf.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P2_GAB_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_CAD_05_DIA_2_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2018_P1_GAB_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'DADOS/',\n 'DADOS/MICRODADOS_ENEM_2018.csv',\n 'DADOS/ITENS_PROVA_2018.csv',\n 'DICION╡RIO/',\n 'DICION╡RIO/Dicionário_Microdados_Enem_2018.ods',\n 'DICION╡RIO/Dicionário_Microdados_Enem_2018.xlsx',\n 'INPUTS/',\n 'INPUTS/INPUT_R_MICRODADOS_ENEM_2018.R',\n 'INPUTS/INPUT_R_ITENS_PROVA_2018.R',\n 'INPUTS/INPUT_SPSS_ITENS_PROVA_2018.sps',\n 'INPUTS/INPUT_SAS_ITENS_PROVA_2018.sas',\n 'INPUTS/INPUT_SPSS_MICRODADOS_ENEM_2018.sps',\n 'INPUTS/INPUT_SAS_MICRODADOS_ENEM_2018.sas']"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2018 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem2018.zip', mode = 'r')\n",
    "enemzip2018.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2018.open('DADOS/MICRODADOS_ENEM_2018.csv') as enem2018:\n",
    "    df_enem2018 = pd.read_csv(enem2018, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['NU_INSCRICAO', 'NU_ANO', 'CO_MUNICIPIO_RESIDENCIA',\n       'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA',\n       'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n       'TP_NACIONALIDADE', 'CO_MUNICIPIO_NASCIMENTO',\n       'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO',\n       'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n       'IN_TREINEIRO', 'CO_ESCOLA', 'CO_MUNICIPIO_ESC',\n       'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC',\n       'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC',\n       'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ',\n       'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA',\n       'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL',\n       'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA',\n       'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE',\n       'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR',\n       'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18',\n       'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS',\n       'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS',\n       'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE',\n       'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO',\n       'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO',\n       'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE',\n       'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA',\n       'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL',\n       'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO',\n       'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'CO_MUNICIPIO_PROVA',\n       'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',\n       'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC',\n       'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n       'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC',\n       'NU_NOTA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH',\n       'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TP_LINGUA',\n       'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC',\n       'TX_GABARITO_MT', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1',\n       'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5',\n       'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006',\n       'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n       'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022',\n       'Q023', 'Q024', 'Q025', 'Q026', 'Q027'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2018.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem 2018 para o Dataframe - 2020-07-11 19:34:03.406728.\nDataframe df_enem2018_completo criado com sucesso - 2020-07-11 19:36:39.276162.\n"
    }
   ],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2018 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2018.open('DADOS/MICRODADOS_ENEM_2018.csv') as enem2018:\n",
    "    df_enem2018_completo = pd.read_csv(enem2018, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2018_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5513747 entries, 0 to 5513746\nColumns: 137 entries, NU_INSCRICAO to Q027\ndtypes: float64(30), int64(64), object(43)\nmemory usage: 5.6+ GB\n"
    }
   ],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2018_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem 2018 para tabela mysql - 2020-07-11 19:36:39.676878.\nTabela tb_enem2018 criada com sucesso - 2020-07-11 20:27:18.366241\nDados importados com sucesso para a tabela tb_enem2018\n"
    }
   ],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2018 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2018_completo.to_sql(\n",
    "    name = 'tb_enem2018',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2018 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Objetos deletados com sucesso - Memória liberada.\n"
    }
   ],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2018_completo)\n",
    "    del(df_enem2018)\n",
    "    del(enem2018)\n",
    "    del(enemzip2018)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['LEIA-ME E DOCUMENTOS TÉCNICOS/',\n 'LEIA-ME E DOCUMENTOS TÉCNICOS/matriz_referencia_enem.pdf',\n 'LEIA-ME E DOCUMENTOS TÉCNICOS/Leia_Me_Enem_2019.pdf',\n 'LEIA-ME E DOCUMENTOS TÉCNICOS/manual_de_redacao_do_enem_2019.pdf',\n 'LEIA-ME E DOCUMENTOS TÉCNICOS/Edital_enem_2019.pdf',\n 'PROVAS E GABARITOS/',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_02_DIA_1_AMARELO_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_02_DIA_1_AMARELO_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_09_DIA_1_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_10_DIA_1_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_02_DIA_1_AMARELO.pdf.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_02_DIA_1_AMARELO_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_02_DIA_1_AMARELO_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_09_DIA_1_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_10_DIA_1_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_05_DIA_2_AMARELO_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_06_DIA_2_CINZA_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_06_DIA_2_CINZA_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_11_DIA_2_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_12_DIA_2_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_06_DIA_2_CINZA_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_06_DIA_2_CINZA_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_11_DIA_2_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_GAB_12_DIA_2_VERDE_LIBRAS.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_01_DIA_1_AZUL_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_09_DIA_1_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_02_DIA_1_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_03_DIA_1_BRANCO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_04_DIA_1_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_09_DIA_1_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_05_DIA_2_AMARELO.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_05_DIA_2_AMARELO_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_05_DIA_2_AMARELO_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_06_DIA_2_CINZA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_CAD_11_DIA_2_LARANJA_LEDOR.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_05_DIA_2_AMARELO_AMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P1_CAD_01_DIA_1_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_01_DIA_1_AZUL_SUPERAMPLIADA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_07_DIA_2_AZUL.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_08_DIA_2_ROSA.pdf',\n 'PROVAS E GABARITOS/ENEM_2019_P2_GAB_11_DIA_2_LARANJA_LEDOR.pdf',\n 'DADOS/',\n 'DADOS/MICRODADOS_ENEM_2019.csv',\n 'DADOS/ITENS_PROVA_2019.csv',\n 'DICION╡RIO/',\n 'DICION╡RIO/Dicionário_Microdados_Enem_2019.ods',\n 'DICION╡RIO/Dicionário_Microdados_Enem_2019.xlsx',\n 'INPUTS/',\n 'INPUTS/INPUT_R_MICRODADOS_ENEM_2019.R',\n 'INPUTS/INPUT_SAS_ITENS_PROVA_2019.sas',\n 'INPUTS/INPUT_SAS_MICRODADOS_ENEM_2019.sas',\n 'INPUTS/INPUT_SPSS_ITENS_PROVA_2019.sps',\n 'INPUTS/INPUT_SPSS_MICRODADOS_ENEM_2019.sps',\n 'INPUTS/INPUT_R_ITENS_PROVA_2019.R']"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#Apresentação dos arquivos dentro da pasta zipada Enem.\n",
    "\n",
    "enemzip2019 = zipfile.ZipFile(r'C:\\Users\\Ricardo\\Downloads\\MicrodadosEnem\\microdados_enem_2019.zip', mode = 'r')\n",
    "enemzip2019.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Processo abaixo, importaremos para o dataframe, apenas para conhecer os dados e verificar o separador do microdado.\n",
    "\n",
    "with enemzip2019.open('DADOS/MICRODADOS_ENEM_2019.csv') as enem2019:\n",
    "    df_enem2019 = pd.read_csv(enem2019, sep = ';', encoding= 'ISO-8859-1', nrows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['NU_INSCRICAO', 'NU_ANO', 'CO_MUNICIPIO_RESIDENCIA',\n       'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA',\n       'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n       'TP_NACIONALIDADE', 'CO_MUNICIPIO_NASCIMENTO',\n       'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO',\n       'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n       'IN_TREINEIRO', 'CO_ESCOLA', 'CO_MUNICIPIO_ESC',\n       'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC',\n       'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC',\n       'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ',\n       'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA',\n       'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL',\n       'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA',\n       'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE',\n       'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR',\n       'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18',\n       'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS',\n       'IN_TEMPO_ADICIONAL', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS',\n       'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE',\n       'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO',\n       'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO',\n       'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE',\n       'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA',\n       'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL',\n       'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO',\n       'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'CO_MUNICIPIO_PROVA',\n       'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',\n       'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC',\n       'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n       'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC',\n       'NU_NOTA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH',\n       'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TP_LINGUA',\n       'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC',\n       'TX_GABARITO_MT', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1',\n       'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5',\n       'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006',\n       'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',\n       'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022',\n       'Q023', 'Q024', 'Q025'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Demonstração das colunas importadas para o dataframe.\n",
    "\n",
    "df_enem2019.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem 2019 para o Dataframe - 2020-07-11 20:27:26.383890.\nDataframe df_enem2019_completo criado com sucesso - 2020-07-11 20:29:27.417906.\n"
    }
   ],
   "source": [
    "# Importação dos dados do Microdados Enem e seleção das colunas para criação do dataframe.\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2019 para o Dataframe - {datetime.now()}.')\n",
    "\n",
    "with enemzip2019.open('DADOS/MICRODADOS_ENEM_2019.csv') as enem2019:\n",
    "    df_enem2019_completo = pd.read_csv(enem2019, sep = ';', encoding = 'ISO-8859-1')\n",
    "\n",
    "print(f'Dataframe df_enem2019_completo criado com sucesso - {datetime.now()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5095270 entries, 0 to 5095269\nColumns: 136 entries, NU_INSCRICAO to Q025\ndtypes: float64(24), int64(71), object(41)\nmemory usage: 5.2+ GB\n"
    }
   ],
   "source": [
    "# Apresentação das informações do Dataframe\n",
    "\n",
    "df_enem2019_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iniciando a criação e importação dos dados do Microdados Enem 2019 para tabela mysql - 2020-07-11 20:29:27.614317.\nTabela tb_enem2019 criada com sucesso - 2020-07-11 21:12:39.227548\nDados importados com sucesso para a tabela tb_enem2019\n"
    }
   ],
   "source": [
    "#Importando o Dataframe para uma tabela no mysql\n",
    "\n",
    "print(f'Iniciando a criação e importação dos dados do Microdados Enem 2019 para tabela mysql - {datetime.now()}.')\n",
    "\n",
    "df_enem2019_completo.to_sql(\n",
    "    name = 'tb_enem2019',\n",
    "    con = engine,\n",
    "    index = False,\n",
    "    chunksize = 10000,\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "\n",
    "print(f'Tabela tb_enem2019 criada com sucesso - {datetime.now()}')\n",
    "print('Dados importados com sucesso para a tabela tb_enem2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Objetos deletados com sucesso - Memória liberada.\n"
    }
   ],
   "source": [
    "#Afim de otimizar a memória da maquina, realizaremos a limpeza dos objetos e liberar a memória da máquina\n",
    "\n",
    "try:\n",
    "    del(df_enem2019_completo)\n",
    "    del(df_enem2019)\n",
    "    del(enem2019)\n",
    "    del(enemzip2019)\n",
    "    print('Objetos deletados com sucesso - Memória liberada.')\n",
    "except NameError as erro:\n",
    "    print('Objetos deletados com sucesso anteriormente - Memória liberada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de importação dos dados necessários para composição de um Dataframe e apresentação dos resultados da analise e plotagem."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594500449906",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}